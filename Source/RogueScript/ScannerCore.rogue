library RogueScript

# Generated by Froley. WARNING: WILL BE OVERWRITTEN.

$include "CompileError.rogue"
$include "ScanTable.rogue"
$include "Token.rogue"
$include "TokenType.rogue"

class ScannerCore [abstract]
  DEFINITIONS
    ip_tokenize_another = 0
    ip_scan_comment = 1
    ip_scan_id_or_keyword = 2
    ip_scan_number = 3
    ip_scan_integer = 4
    ip_scan_binary_integer = 5
    ip_scan_octal_integer = 6
    ip_scan_hex_integer = 7
    ip_tokenize_string = 8
    ip_scan_string = 9
    ip_tokenize_character_or_string = 10
    ip_scan_single_quote_string = 11
    ip_tokenize_two_quote_string = 12
    ip_scan_two_quote_string = 13
    ip_scan_character = 14
    ip_read_hex4 = 15
    ip_read_hex2 = 16
    ip_read_hex_digit = 17
    ip_tokenize_verbatim_string = 18
    ip_scan_verbatim_string = 19

  PROPERTIES
    _filepath     : String
    _scanner      : Rogue::Scanner
    line          = 1
    column        = 1

    tokens        : Token[]
    buffer        = String()
    output        = String()

    start_ip      = 0
    halt          = false

    _position_stack  = Int[]
    _line_stack      = Int[]
    _column_stack    = Int[]
    _token_pos_stack = Int[]

    # GENERATED PROPERTIES
    ch           : Character
    count        : Int
    saved_buffer : String
    base         : Int
    hex2         : Int
    hex4         : Int
    hex_digit    : Int
    value        : Int
    digits       : Int
    _scan_pattern_0 = ScanPattern( "[ \r\t]*" )
    _scan_pattern_1 = ScanPattern( "{[_a-zA-Z][_a-zA-Z0-9]*}" )
    _scan_pattern_2 = ScanPattern( "[0-9]*" )
    _scan_pattern_3 = ScanPattern( "[^\n]*" )
    _scan_pattern_4 = ScanPattern( "{----[-]*}" )
    _scan_pattern_5 = ScanPattern( "{====[=]*}" )
    _scan_pattern_6 = ScanPattern( "[ ]+" )
    _scan_pattern_7 = ScanPattern( "[0-9]" )
    _scan_pattern_8 = ScanPattern( "{[.][0-9]}" )
    _scan_pattern_9 = ScanPattern( "{[iIlL]}" )
    _scan_pattern_10 = ScanPattern( "{[fFrR]}" )
    _scan_pattern_11 = ScanPattern( "{[eE]}" )
    _scan_pattern_12 = ScanPattern( "[+-]" )
    _scan_pattern_13 = ScanPattern( "[0-9]+" )
    _scan_pattern_14 = ScanPattern( "[_]+" )
    _scan_pattern_15 = ScanPattern( "[01]+" )
    _scan_pattern_16 = ScanPattern( "[0-7]+" )
    _scan_pattern_17 = ScanPattern( "[0-9A-Fa-f]+" )
    _scan_pattern_18 = ScanPattern( "[0-9a-fA-F]" )
    _scan_pattern_19 = ScanPattern( "[ \t]*" )
    _scan_table_0 = ScanTable("iRb/Hgo+IkAnQkBIJGomhzgthz4qh0xch1Ihh1Reh1p9h2Bdh2Iph2Q6h2YsiBg8iBo/iCguiDJ8iEhbiFI9iFw+iGZ7iHAoiHIliHQriHo7iQQviQZ+iRAAAAEAAgEnRgMAJgR8UltUe1Z0WAQAOAA5AP8Bclz/AWFg/wFjZP8BZWhZAP8KZIEAZYE6ZoIwaYJqc4Q8bIUWbYVwcoYCdIZcdYcW/wFlgQT/AWaBCP8CYYEOaYEw/wF1gRL/AWyBFv8BdIEa/wFWgR7/AWGBIv8BbIEm/wF1gSr/AWWBLgUA/wFugTT/AWWBOAYA/wNsgUJugVR4gh7/AXOBRv8BZYFK/wFJgU7/AWaBUgcA/wFkgVj/A0mBYEyBZk2CDP8BZoFkCAD/AW+Bav8BY4Fu/wFhgXL/AWyBdv8BTYF6/wFhgX7/AWOCAv8BcoIG/wFvggoJAP8BYYIQ/wFjghT/AXKCGP8Bb4IcCgD/AWmCIv8Bc4Im/wF0gir/AXOCLgsA/wFpgjT/AWyCOP8BZYI8/wJCgkJTglT/AXmCRv8BdIJK/wFlgk7/AXOCUgwA/wF0glj/AXKCXP8BaYJg/wFugmT/AWeCaA0A/wRmgnRugnZzgyRkhDoOAP8BY4J6/wFsgn7/AXWDAv8BZIMG/wFlgwoPAUaDDv8Bb4MS/wFsgxb/AWSDGv8BZYMe/wFygyIQAP8FQ4MwRINORYNoUIN2UoQY/wFvgzT/AW2DOP8BcIM8/wFvg0D/AXWDRP8BboNI/wFkg0wRAP8BZYNS/wFmg1b/AWmDWv8BboNe/wFlg2L/AWSDZhIA/wFug2z/AXWDcP8BbYN0EwD/AXKDev8BaYN+/wFthAL/AWmEBv8BdIQK/wFphA7/AXaEEv8BZYQWFAD/AWWEHP8BZoQg/wFlhCT/AXKEKP8BZYQs/wFuhDD/AWOENP8BZYQ4FQAWAP8CdIRCb4RU/wFyhEb/AWmESv8BboRO/wFnhFIXAP8BdYRY/wFyhFz/AWOEYP8BZYRk/wJGhGpMhQj/AWmEbv8BbIRy/wFlhHb/AXCEev8BYYR+/wF0hQL/AWiFBh4A/wFphQz/AW6FEP8BZYUUHwD/AW+FGv8CY4Ugd4VW/wFhhST/AWyFKP8CRIUuTYVE/wFlhTL/AWaFNv8BaYU6/wFuhT7/AWWFQhgA/wFhhUj/AWOFTP8BcoVQ/wFvhVQZAP8BZYVa/wFyhV7/AWOFYv8BYYVm/wFzhWr/AWWFbhoA/wFhhXT/AWOFeP8BcoV8/wFvhgAbAP8CZYYIb4Yy/wFxhgz/AXWGEP8BaYYU/wFyhhj/AWWGHP8BUoYg/wFvhiT/AWeGKP8BdYYs/wFlhjAcAP8BZ4Y2/wF1hjr/AWWGPv8BVoZC/wFlhkb/AXKGSv8Bc4ZO/wFphlL/AW+GVv8BboZaHQD/AmGGYmiGdP8BcoZm/wFnhmr/AWWGbv8BdIZyIAD/AWmGeP8Bc4Z8/wFNhwD/AW+HBP8BZIcI/wF1hwz/AWyHEP8BZYcUIQD/AXCHGv8BcIce/wFlhyL/AXKHJv8BY4cq/wFhhy7/AXOHMv8BZYc2IgAjAT2HPGIARQM+h0Yth0g9h0okAEYAXQAlAT2HUF4AJwAoAT2HWEcAKQE9h15hACoAKwAsAC0DOoduPIdwPod+LgD/ATyHdP8BOod4QQE9h3xlAP8BPogC/wI6iAg+iA5SAT2IDGYA/wE6iBJUAT2IFmcALwBDAz6IIj2IJDyIJjAAQABEAFACLoguOogwMQBRAE0DLog6W4hEPYhGMgI8iEA+iEIzADQANQBoAFsCfIhOPYhQNgBjAEkCXYhYPohaNwBKADsCPYhiPohkOgA8AD4CPYhsPohuPQA/AEgASwBMAT2IeGAATgIriQA9iQJPAFwAVgBXAi+JDD2JDlgAXwBaAT2JFGQA")
    _scan_table_1 = ScanTable("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")
    _scan_table_2 = ScanTable("YgABRwT/AUwI/wFPDP8BQhD/AUEU/wFMGP8BIBz/AlAiTUj/AVIm/wFPKv8BUC7/AUUy/wFSNv8BVDr/AUk+/wFFQv8BU0YBAP8BRUz/AVRQ/wFIVP8BT1j/AURc/wFTYAIA")
    _scan_table_3 = ScanTable("EgABMAT/A2IMYw54EAEAAgADAA==")

  METHODS
    method init
      noAction

    method init( file:File, line=1, column=1 )
      init( file.filepath, Rogue::Scanner(file).[line=line, column=column] )

    method init( filepath:String, content:String, line=1, column=1 )
      init( filepath, Rogue::Scanner(content).[line=line, column=column] )

    method init( _filepath, _scanner, line=1, column=1 )
      noAction

    method reset
      if (_scanner) _scanner.reset
      line   = 1
      column = 1
      tokens = null
      buffer.clear
      output.clear
      start_ip = 0
      halt = false
      _position_stack.clear
      _line_stack.clear
      _column_stack.clear
      _token_pos_stack.clear

    method reset( file:File, line=1:Int, column=1:Int )
      reset
      init( file, line, column )

    method reset( filepath:String, content:String, line=1:Int, column=1:Int )
      reset
      init( filepath, content, line, column )

    method execute( ip:Int )
      _clear_state
      _execute( ip )

    method tokenize( file:File, line=1, column=1, &ip=null:Int? )->Token[]
      return tokenize( file.filepath, Rogue::Scanner(file) )

    method tokenize( filepath:String, content:String, line=1, column=1, &ip=null:Int? )->Token[]
      return tokenize( filepath, Rogue::Scanner(content).[line=line, column=column] )

    method tokenize( _filepath, _scanner, line=1, column=1, &ip=null:Int? )->Token[]
      reset
      return tokenize( ip )

    method tokenize( ip=null:Int? )->Token[]
      tokens = Token[]
      if (ip) start_ip = ip.value
      _clear_state
      while (_execute(start_ip) or not halt)
        buffer.clear
      endWhile
      _on_output_line # flush any buffered output
      return tokens

    method _add( type:TokenType )
      if (type.attributes & TokenType.ATTRIBUTE_CONTENT)
        tokens.add( _t(type,buffer.cloned) )
      else
        tokens.add( _t(type) )
      endIf
      buffer.clear

    method _clear_state
      tokens = Token[]
      buffer.clear
      output.clear
      halt = false

    method _describe_character( c:Character )->String
      if (c == 10 or c == 13)       return "end of line";
      elseIf (c >= 32 and c != 127) return "'$'" (c)
      else                          return "'$'" (c.to_escaped_ascii)

    method _discard_position
      if (_position_stack.is_empty)
        _throw_syntax_error( "discardPosition without prior savePosition." )
      endIf
      _position_stack.remove_last
      _line_stack.remove_last
      _column_stack.remove_last
      _token_pos_stack.remove_last

    method _is_next( text:String )->Logical
      local location = _scanner.location
      local result = _scanner.consume( text )
      _scanner.location = location
      return result

    method _must_consume( ch:Character )
      if (_scanner.consume(ch)) return
      local message = "Syntax error - expected $, found " (_describe_character(ch))
      if (_scanner.has_another) message += _describe_character(_scanner.peek) + "."
      else                      message += "end of input."
      throw CompileError( message, _filepath, _scanner.source, _scanner.line, _scanner.column )

    method _must_consume( st:String )
      if (_scanner.consume(st)) return
      _throw_expected_string_error( "'$'" (st.to_escaped_ascii("'")) )

    method _must_consume( pattern:ScanPattern )
      if (pattern.scan(_scanner)) return
      _throw_expected_string_error( pattern->String )

    method _next_is( text:String )->Logical
      if (not _scanner.has_another(text.count)) return false
      local pos = _scanner.position
      forEach (ch at index in text)
        if (ch != _scanner.data[pos+index]) return false
      endForEach
      return true

    method _on_output_line
      # Default behavior: print out 'output' and clear it. Can override this method.
      print( output )
      flush
      output.clear

    method _restore_position
      if (_position_stack.is_empty)
        _throw_syntax_error( "restorePosition without prior savePosition." )
      endIf
      _scanner.position = _position_stack.remove_last
      _scanner.line     = _line_stack.remove_last
      _scanner.column   = _column_stack.remove_last
      tokens.discard_from( _token_pos_stack.remove_last )

    method _save_position
      _position_stack.add( _scanner.position )
      _line_stack.add( _scanner.line )
      _column_stack.add( _scanner.column )
      _token_pos_stack.add( tokens.count )

    method _scan( ch:Character )->Logical
      if (not _scanner.consume(ch)) return false
      buffer.print ch
      return true

    method _scan( text:String )->Logical
      if (not _scanner.consume(text)) return false
      buffer.print text
      return true

    method _t( type:TokenType, content=null:String )->Token
      return Token( type, _filepath, _scanner.source, line, column, content )

    method _throw_expected_string_error( st:String )
      local message = "Syntax error - expected $, found " (st)
      if (_scanner.has_another) message += _describe_character(_scanner.peek) + "."
      else                      message += "end of input."
      throw CompileError( message, _filepath, _scanner.source, _scanner.line, _scanner.column )

    method _throw_syntax_error( message=null:String )
      if (not message)
        local builder = String()
        builder.print "Syntax error - unexpected "
        if (not _scanner.has_another)
          builder.println "end of input."
        else
          builder.[ print(_describe_character(_scanner.peek)), print('.') ]
        endIf
        message = builder
      endIf
      throw CompileError( message, _filepath, _scanner.source, _scanner.line, _scanner.column )

    method _execute( ip:Int )->Logical
      which (ip)
        case ip_tokenize_another: return r_tokenize_another
        case ip_scan_comment: return r_scan_comment
        case ip_scan_id_or_keyword: return r_scan_id_or_keyword
        case ip_scan_number: return r_scan_number
        case ip_scan_integer: return r_scan_integer
        case ip_scan_binary_integer: return r_scan_binary_integer
        case ip_scan_octal_integer: return r_scan_octal_integer
        case ip_scan_hex_integer: return r_scan_hex_integer
        case ip_tokenize_string: return r_tokenize_string
        case ip_scan_string: return r_scan_string
        case ip_tokenize_character_or_string: return r_tokenize_character_or_string
        case ip_scan_single_quote_string: return r_scan_single_quote_string
        case ip_tokenize_two_quote_string: return r_tokenize_two_quote_string
        case ip_scan_two_quote_string: return r_scan_two_quote_string
        case ip_scan_character: return r_scan_character
        case ip_read_hex4: return r_read_hex4
        case ip_read_hex2: return r_read_hex2
        case ip_read_hex_digit: return r_read_hex_digit
        case ip_tokenize_verbatim_string: return r_tokenize_verbatim_string
        case ip_scan_verbatim_string: return r_scan_verbatim_string
        others
          halt = true
          return false
      endWhich

    method r_tokenize_another->Logical
      ch = _scanner.peek
      if ((((ch==' ') or (ch=='\r')) or (ch=='\t')))
        _scan_pattern_0.scan(_scanner)
      endIf
      line   = _scanner.line
      column = _scanner.column
      ch = _scanner.peek
      if ((((ch=='#') or ((ch=='-') and _next_is("----"))) or ((ch=='=') and _next_is("===="))))
        if (not r_scan_comment) return false
      endIf
      if ((not _scanner.has_another))
        _add( TokenType.EOL )
        halt = true
        return false
      endIf
      if (((ch=='.') and _scanner.consume("...")))
        while ((_scanner.has_another and (not _scanner.consume('\n'))))
          if ((not (_scanner.consume(' ') or _scanner.consume('\t'))))
            if (_scanner.next_is('#'))
              if (not r_scan_comment) return false
              return false
            endIf
            _throw_syntax_error("End of line expected.")
            return false
          endIf
        endWhile
        return false
      endIf
      if (((((ch>='a') and (ch<='z')) or ((ch>='A') and (ch<='Z'))) or (ch=='_')))
        if (not r_scan_id_or_keyword) return false
      endIf
      _scan_table_0.reset
      contingent
        block n=1
          while (_scanner.has_another(n))
            if (not _scan_table_0.accept(_scanner.peek(n-1)))
              escapeWhile
            endIf
            ++n
          endWhile
          necessary (_scan_table_0.has_product)
          loop (_scan_table_0.match_count) _scanner.read
        endBlock
        which (_scan_table_0.product)
          case 0
            _add( TokenType.EOL )
            return false
          case 1
            if (not r_tokenize_string) return false
          case 2
            if (not r_tokenize_character_or_string) return false
          case 3
            if (not r_tokenize_two_quote_string) return false
          case 4
            if (not r_tokenize_verbatim_string) return false
          case 5
            _add( TokenType.META_DEFAULT_VALUE )
            return false
          case 6
            _add( TokenType.META_DEFINE )
            return false
          case 7
            _add( TokenType.META_ELSE_IF )
            return false
          case 8
            _add( TokenType.META_END_IF )
            return false
          case 9
            _add( TokenType.META_END_LOCAL_MACRO )
            return false
          case 10
            _add( TokenType.META_END_MACRO )
            return false
          case 11
            _add( TokenType.META_EXISTS )
            return false
          case 12
            _add( TokenType.META_FILE_BYTES )
            return false
          case 13
            _add( TokenType.META_FILE_STRING )
            return false
          case 14
            _add( TokenType.META_IF )
            return false
          case 15
            _add( TokenType.META_INCLUDE )
            return false
          case 16
            _add( TokenType.META_INCLUDE_FOLDER )
            return false
          case 17
            _add( TokenType.META_IS_COMPOUND )
            return false
          case 18
            _add( TokenType.META_IS_DEFINED )
            return false
          case 19
            _add( TokenType.META_IS_ENUM )
            return false
          case 20
            _add( TokenType.META_IS_PRIMITIVE )
            return false
          case 21
            _add( TokenType.META_IS_REFERENCE )
            return false
          case 22
            _add( TokenType.META_JOIN_IDS )
            return false
          case 23
            _add( TokenType.META_JOIN_STRINGS )
            return false
          case 24
            _add( TokenType.META_LOCAL_DEFINE )
            return false
          case 25
            _add( TokenType.META_LOCAL_MACRO )
            return false
          case 26
            _add( TokenType.META_LOWERCASE )
            return false
          case 27
            _add( TokenType.META_MACRO )
            return false
          case 28
            _add( TokenType.META_REQUIRE_ROGUE )
            return false
          case 29
            _add( TokenType.META_ROGUE_VERSION )
            return false
          case 30
            _add( TokenType.META_SOURCE_FILEPATH )
            return false
          case 31
            _add( TokenType.META_SOURCE_LINE )
            return false
          case 32
            _add( TokenType.META_TARGET )
            return false
          case 33
            _add( TokenType.META_THIS_MODULE )
            return false
          case 34
            _add( TokenType.META_UPPERCASE )
            return false
          case 35
            _add( TokenType.SYMBOL_AMPERSAND )
            return false
          case 36
            _add( TokenType.SYMBOL_ARROW )
            return false
          case 37
            _add( TokenType.SYMBOL_ASTERISK )
            return false
          case 38
            _add( TokenType.SYMBOL_AT )
            return false
          case 39
            _add( TokenType.SYMBOL_BACKSLASH )
            return false
          case 40
            _add( TokenType.SYMBOL_BANG )
            return false
          case 41
            _add( TokenType.SYMBOL_CARET )
            return false
          case 42
            _add( TokenType.SYMBOL_CLOSE_CURLY )
            return false
          case 43
            _add( TokenType.SYMBOL_CLOSE_SQUARE )
            return false
          case 44
            _add( TokenType.SYMBOL_CLOSE_PAREN )
            return false
          case 45
            _add( TokenType.SYMBOL_COLON )
            return false
          case 46
            _add( TokenType.SYMBOL_COLON_COLON )
            return false
          case 47
            _add( TokenType.SYMBOL_COMMA )
            return false
          case 48
            _add( TokenType.SYMBOL_COMPARE )
            return false
          case 49
            _add( TokenType.SYMBOL_QUESTION_DOT )
            return false
          case 50
            _add( TokenType.SYMBOL_DOTDOT )
            return false
          case 51
            _add( TokenType.SYMBOL_DOTDOTLT )
            return false
          case 52
            _add( TokenType.SYMBOL_DOTDOTGT )
            return false
          case 53
            _add( TokenType.SYMBOL_DOT_OPEN_SQUARE )
            return false
          case 54
            _add( TokenType.SYMBOL_DOUBLE_VERTICAL_BAR )
            return false
          case 55
            _add( TokenType.SYMBOL_EMPTY_SQUARE_BRACKETS )
            return false
          case 56
            _add( TokenType.SYMBOL_VALUE_LIST )
            return false
          case 57
            _add( TokenType.SYMBOL_VALUE_TABLE )
            return false
          case 58
            _add( TokenType.SYMBOL_EQ )
            return false
          case 59
            _add( TokenType.SYMBOL_EQUALS )
            return false
          case 60
            _add( TokenType.SYMBOL_FAT_ARROW )
            return false
          case 61
            _add( TokenType.SYMBOL_GE )
            return false
          case 62
            _add( TokenType.SYMBOL_GT )
            return false
          case 63
            _add( TokenType.SYMBOL_GTGT )
            return false
          case 64
            _add( TokenType.SYMBOL_LE )
            return false
          case 65
            _add( TokenType.SYMBOL_LEFT_SHIFT )
            return false
          case 66
            _add( TokenType.SYMBOL_LEFT_SHIFT_EQUALS )
            return false
          case 67
            _add( TokenType.SYMBOL_LT )
            return false
          case 68
            _add( TokenType.SYMBOL_LTLT )
            return false
          case 69
            _add( TokenType.SYMBOL_MINUS )
            return false
          case 70
            _add( TokenType.SYMBOL_MINUS_MINUS )
            return false
          case 71
            _add( TokenType.SYMBOL_NE )
            return false
          case 72
            _add( TokenType.SYMBOL_OPEN_CURLY )
            return false
          case 73
            _add( TokenType.SYMBOL_OPEN_SQUARE )
            return false
          case 74
            _add( TokenType.SYMBOL_OPEN_SQUARE_GT )
            return false
          case 75
            _add( TokenType.SYMBOL_OPEN_PAREN )
            return false
          case 76
            _add( TokenType.SYMBOL_PERCENT )
            return false
          case 77
            _add( TokenType.SYMBOL_PERIOD )
            return false
          case 78
            _add( TokenType.SYMBOL_PLUS )
            return false
          case 79
            _add( TokenType.SYMBOL_PLUS_PLUS )
            return false
          case 80
            _add( TokenType.SYMBOL_QUESTION )
            return false
          case 81
            _add( TokenType.SYMBOL_QUESTION_COLON )
            return false
          case 82
            _add( TokenType.SYMBOL_RIGHT_SHIFT )
            return false
          case 83
            _add( TokenType.SYMBOL_RIGHT_SHIFT_EQUALS )
            return false
          case 84
            _add( TokenType.SYMBOL_RIGHT_SHIFT_X )
            return false
          case 85
            _add( TokenType.SYMBOL_RIGHT_SHIFT_X_EQUALS )
            return false
          case 86
            _add( TokenType.SYMBOL_SEMICOLON )
            return false
          case 87
            _add( TokenType.SYMBOL_SLASH )
            return false
          case 88
            _add( TokenType.SYMBOL_SLASH_SLASH )
            return false
          case 89
            _add( TokenType.SYMBOL_BRIEF_TRACE )
            return false
          case 90
            _add( TokenType.SYMBOL_TILDE )
            return false
          case 91
            _add( TokenType.SYMBOL_VERTICAL_BAR )
            return false
          case 92
            _add( TokenType.SYMBOL_PLUS_EQUALS )
            return false
          case 93
            _add( TokenType.SYMBOL_MINUS_EQUALS )
            return false
          case 94
            _add( TokenType.SYMBOL_TIMES_EQUALS )
            return false
          case 95
            _add( TokenType.SYMBOL_DIVIDE_EQUALS )
            return false
          case 96
            _add( TokenType.SYMBOL_MOD_EQUALS )
            return false
          case 97
            _add( TokenType.SYMBOL_POWER_EQUALS )
            return false
          case 98
            _add( TokenType.SYMBOL_BITWISE_AND_EQUALS )
            return false
          case 99
            _add( TokenType.SYMBOL_BITWISE_OR_EQUALS )
            return false
          case 100
            _add( TokenType.SYMBOL_BITWISE_XOR_EQUALS )
            return false
          case 101
            _add( TokenType.SYMBOL_SHIFT_LEFT_EQUALS )
            return false
          case 102
            _add( TokenType.SYMBOL_SHIFT_RIGHT_EQUALS )
            return false
          case 103
            _add( TokenType.SYMBOL_SHIFT_RIGHT_X_EQUALS )
            return false
          case 104
            _add( TokenType.SYMBOL_ACCESS_EQUALS )
            return false
          others
            necessary (false)
        endWhich
      endContingent
      if ((ch=='$'))
        _scan('$')
        if (_scan_pattern_1.scan(_scanner,buffer))
          _add( TokenType.PLACEHOLDER )
          return false
        endIf
        if (_scan_pattern_2.scan(_scanner,buffer))
          _add( TokenType.GENERIC_FN_ARG )
          return false
        endIf
        _add( TokenType.SYMBOL_DOLLAR )
        return false
      endIf
      if (not r_scan_number) return false
      _throw_syntax_error
      return false

    method r_scan_comment->Logical
      if (_scan('#'))
        if (_scan('{'))
          count = 1
          while (_scanner.has_another)
            ch = _scanner.read
            buffer.print(ch)
            if ((ch=='\n'))
              saved_buffer = buffer
              _add( TokenType.EOL )
              buffer.clear
              buffer.print saved_buffer
            elseIf ((ch=='#'))
              if (_scan('{'))
                ++count
              endIf
            elseIf ((ch=='}'))
              if (_scan('#'))
                --count
                if ((count==0))
                  return false
                endIf
              endIf
            endIf
          endWhile
          _throw_syntax_error("Unterminated multi-line comment.")
          return false
        else
          if (_scan_pattern_3.scan(_scanner,buffer))
            _scanner.consume('\n')
            _add( TokenType.EOL )
            return false
          endIf
        endIf
      elseIf ((_scan_pattern_4.scan(_scanner) or _scan_pattern_5.scan(_scanner)))
        _scan_pattern_3.scan(_scanner,buffer)
        _scanner.consume('\n')
        _add( TokenType.EOL )
        return false
      else
        return true
      endIf
      return true

    method r_scan_id_or_keyword->Logical
      if ((not _scan_pattern_1.scan(_scanner,buffer)))
        return true
      endIf
      _scan_table_1.reset
      contingent
        necessary (_scan_table_1.accept(forEach in buffer))
        which (_scan_table_1.product)
          case 1
            if (_scan_pattern_6.scan(_scanner))
              buffer.print(' ')
              if (_scan_pattern_1.scan(_scanner,buffer))
                _scan_table_2.reset
                contingent
                  necessary (_scan_table_2.accept(forEach in buffer))
                  which (_scan_table_2.product)
                    case 1
                      _add( TokenType.KEYWORD_GLOBAL_PROPERTIES )
                      return false
                    case 2
                      _add( TokenType.KEYWORD_GLOBAL_METHODS )
                      return false
                    others
                      necessary (false)
                  endWhich
                unsatisfied
                  _throw_syntax_error("Expected 'GLOBAL PROPERTIES' or 'GLOBAL METHODS'.")
                  return false
                endContingent
              endIf
            endIf
          case 2
            _add( TokenType.KEYWORD_AND )
            return false
          case 3
            _add( TokenType.KEYWORD_ASSERT )
            return false
          case 4
            _add( TokenType.KEYWORD_AUGMENT )
            return false
          case 5
            _add( TokenType.KEYWORD_BLOCK )
            return false
          case 6
            _add( TokenType.KEYWORD_CASE )
            return false
          case 7
            _add( TokenType.KEYWORD_CATCH )
            return false
          case 8
            _add( TokenType.KEYWORD_CATEGORIES )
            return false
          case 9
            _add( TokenType.KEYWORD_CLASS )
            return false
          case 10
            _add( TokenType.KEYWORD_CONTINGENT )
            return false
          case 11
            _add( TokenType.KEYWORD_DEFINITIONS )
            return false
          case 12
            _add( TokenType.KEYWORD_DOWN_TO )
            return false
          case 13
            _add( TokenType.KEYWORD_ELSE )
            return false
          case 14
            _add( TokenType.KEYWORD_ELSE_IF )
            return false
          case 15
            _add( TokenType.KEYWORD_END_AUGMENT )
            return false
          case 16
            _add( TokenType.KEYWORD_END_BLOCK )
            return false
          case 17
            _add( TokenType.KEYWORD_END_CLASS )
            return false
          case 18
            _add( TokenType.KEYWORD_END_CONTINGENT )
            return false
          case 19
            _add( TokenType.KEYWORD_END_ENUM )
            return false
          case 20
            _add( TokenType.KEYWORD_END_FOR_EACH )
            return false
          case 21
            _add( TokenType.KEYWORD_END_FUNCTION )
            return false
          case 22
            _add( TokenType.KEYWORD_END_IF )
            return false
          case 23
            _add( TokenType.KEYWORD_END_LOOP )
            return false
          case 24
            _add( TokenType.KEYWORD_END_ROUTINE )
            return false
          case 25
            _add( TokenType.KEYWORD_END_SUBCLASS )
            return false
          case 26
            _add( TokenType.KEYWORD_END_TEMPORARILY )
            return false
          case 27
            _add( TokenType.KEYWORD_END_TRY )
            return false
          case 28
            _add( TokenType.KEYWORD_END_USE )
            return false
          case 29
            _add( TokenType.KEYWORD_END_WHICH )
            return false
          case 30
            _add( TokenType.KEYWORD_END_WHILE )
            return false
          case 31
            _add( TokenType.KEYWORD_ENUM )
            return false
          case 32
            _add( TokenType.KEYWORD_ENSURE )
            return false
          case 33
            _add( TokenType.KEYWORD_ESCAPE_BLOCK )
            return false
          case 34
            _add( TokenType.KEYWORD_ESCAPE_CONTINGENT )
            return false
          case 35
            _add( TokenType.KEYWORD_ESCAPE_FOR_EACH )
            return false
          case 36
            _add( TokenType.KEYWORD_ESCAPE_IF )
            return false
          case 37
            _add( TokenType.KEYWORD_ESCAPE_LOOP )
            return false
          case 38
            _add( TokenType.KEYWORD_ESCAPE_TRY )
            return false
          case 39
            _add( TokenType.KEYWORD_ESCAPE_WHICH )
            return false
          case 40
            _add( TokenType.KEYWORD_ESCAPE_WHILE )
            return false
          case 41
            _add( TokenType.KEYWORD_EXPORT )
            return false
          case 42
            _add( TokenType.KEYWORD_FALSE )
            return false
          case 43
            _add( TokenType.KEYWORD_FOR_EACH )
            return false
          case 44
            _add( TokenType.KEYWORD_FUNCTION )
            return false
          case 45
            _add( TokenType.KEYWORD_FUNCTION_TYPE )
            return false
          case 46
            _add( TokenType.KEYWORD_GLOBAL_PROPERTIES )
            return false
          case 47
            _add( TokenType.KEYWORD_GLOBAL_METHODS )
            return false
          case 48
            _add( TokenType.KEYWORD_IF )
            return false
          case 49
            _add( TokenType.KEYWORD_IMPORT )
            return false
          case 50
            _add( TokenType.KEYWORD_INSTANCE_OF )
            return false
          case 51
            _add( TokenType.KEYWORD_IS )
            return false
          case 52
            _add( TokenType.KEYWORD_IS_TYPE )
            return false
          case 53
            _add( TokenType.KEYWORD_LOCAL )
            return false
          case 54
            _add( TokenType.KEYWORD_LOCALIZE )
            return false
          case 55
            _add( TokenType.KEYWORD_LOOP )
            return false
          case 56
            _add( TokenType.KEYWORD_METHOD )
            return false
          case 57
            _add( TokenType.KEYWORD_METHODS )
            return false
          case 58
            _add( TokenType.KEYWORD_MODULE )
            return false
          case 59
            _add( TokenType.KEYWORD_NATIVE_SECTION )
            return false
          case 60
            _add( TokenType.KEYWORD_NATIVE )
            return false
          case 61
            _add( TokenType.KEYWORD_NATIVE_HEADER )
            return false
          case 62
            _add( TokenType.KEYWORD_NATIVE_CODE )
            return false
          case 63
            _add( TokenType.KEYWORD_NATIVE_TYPE )
            return false
          case 64
            _add( TokenType.KEYWORD_NECESSARY )
            return false
          case 65
            _add( TokenType.KEYWORD_NEW )
            return false
          case 66
            _add( TokenType.KEYWORD_NEXT_ITERATION )
            return false
          case 67
            _add( TokenType.KEYWORD_NO_ACTION )
            return false
          case 68
            _add( TokenType.KEYWORD_NOT )
            return false
          case 69
            _add( TokenType.KEYWORD_NULL )
            return false
          case 70
            _add( TokenType.KEYWORD_OR )
            return false
          case 71
            _add( TokenType.KEYWORD_OTHERS )
            return false
          case 72
            _add( TokenType.KEYWORD_PI )
            return false
          case 73
            _add( TokenType.KEYWORD_PRIOR )
            return false
          case 74
            _add( TokenType.KEYWORD_PROPERTIES )
            return false
          case 75
            _add( TokenType.KEYWORD_RETURN )
            return false
          case 76
            _add( TokenType.KEYWORD_ROUTINE )
            return false
          case 77
            _add( TokenType.KEYWORD_SATISFIED )
            return false
          case 78
            _add( TokenType.KEYWORD_STATES )
            return false
          case 79
            _add( TokenType.KEYWORD_SUBCLASS )
            return false
          case 80
            _add( TokenType.KEYWORD_SUFFICIENT )
            return false
          case 81
            _add( TokenType.KEYWORD_SWAP_VALUES )
            return false
          case 82
            _add( TokenType.KEYWORD_TEMPORARILY )
            return false
          case 83
            _add( TokenType.KEYWORD_THIS )
            return false
          case 84
            _add( TokenType.KEYWORD_THIS_TYPE )
            return false
          case 85
            _add( TokenType.KEYWORD_THROW )
            return false
          case 86
            _add( TokenType.KEYWORD_TRACE )
            return false
          case 87
            _add( TokenType.KEYWORD_TRUE )
            return false
          case 88
            _add( TokenType.KEYWORD_TRY )
            return false
          case 89
            _add( TokenType.KEYWORD_UNDEFINED )
            return false
          case 90
            _add( TokenType.KEYWORD_UNSATISFIED )
            return false
          case 91
            _add( TokenType.KEYWORD_USE )
            return false
          case 92
            _add( TokenType.KEYWORD_USES )
            return false
          case 93
            _add( TokenType.KEYWORD_WHICH )
            return false
          case 94
            _add( TokenType.KEYWORD_WHILE )
            return false
          case 95
            _add( TokenType.KEYWORD_WITH )
            return false
          case 96
            _add( TokenType.KEYWORD_XOR )
            return false
          others
            necessary (false)
        endWhich
      unsatisfied
        _add( TokenType.IDENTIFIER )
        return false
      endContingent
      return true

    method r_scan_number->Logical
      if (((not _scan_pattern_7.is_next(_scanner)) or _scan_pattern_8.is_next(_scanner)))
        return true
      endIf
      _scan_table_3.reset
      contingent
        block n=1
          while (_scanner.has_another(n))
            if (not _scan_table_3.accept(_scanner.peek(n-1)))
              escapeWhile
            endIf
            ++n
          endWhile
          necessary (_scan_table_3.has_product)
          loop (_scan_table_3.match_count) _scanner.read
        endBlock
        which (_scan_table_3.product)
          case 1
            base = 2
            if (not r_scan_binary_integer) return false
            _scan_pattern_9.scan(_scanner,buffer)
            _add( TokenType.BINARY_INTEGER )
            return false
          case 2
            base = 8
            if (not r_scan_octal_integer) return false
            _scan_pattern_9.scan(_scanner,buffer)
            _add( TokenType.OCTAL_INTEGER )
            return false
          case 3
            base = 16
            if (not r_scan_hex_integer) return false
            _scan_pattern_9.scan(_scanner,buffer)
            _add( TokenType.HEX_INTEGER )
            return false
          others
            necessary (false)
        endWhich
      unsatisfied
        if (not r_scan_integer) return false
        if (_scanner.next_is('.'))
          ch = _scanner.peek (1)
          if ((((((ch>='a') and (ch<='z')) or ((ch>='A') and (ch<='Z'))) or (ch=='_')) or (ch=='.')))
            _add( TokenType.INTEGER )
            return false
          endIf
        endIf
        if (_scan_pattern_9.scan(_scanner,buffer))
          _add( TokenType.INTEGER )
          return false
        endIf
        if (_scan_pattern_10.scan(_scanner,buffer))
          _add( TokenType.REAL_NUMBER )
          return false
        endIf
        if ((not _scan('.')))
          _add( TokenType.INTEGER )
          return false
        endIf
        if (not r_scan_integer) return false
        if (_scan_pattern_11.scan(_scanner,buffer))
          _scan_pattern_12.scan(_scanner,buffer)
          if ((not _scan_pattern_13.scan(_scanner,buffer)))
            _throw_syntax_error("Integer exponent expected.")
            return false
          endIf
        endIf
        _scan_pattern_10.scan(_scanner,buffer)
        _add( TokenType.REAL_NUMBER )
        return false
      endContingent

    method r_scan_integer->Logical
      while (_scan_pattern_13.scan(_scanner,buffer))
        if ((not _scan_pattern_14.scan(_scanner)))
          return true
        endIf
      endWhile
      return true

    method r_scan_binary_integer->Logical
      while (_scan_pattern_15.scan(_scanner,buffer))
        if ((not _scan_pattern_14.scan(_scanner)))
          return true
        endIf
      endWhile
      return true

    method r_scan_octal_integer->Logical
      while (_scan_pattern_16.scan(_scanner,buffer))
        if ((not _scan_pattern_14.scan(_scanner)))
          return true
        endIf
      endWhile
      return true

    method r_scan_hex_integer->Logical
      while (_scan_pattern_17.scan(_scanner,buffer))
        if ((not _scan_pattern_14.scan(_scanner)))
          return true
        endIf
      endWhile
      return true

    method r_tokenize_string->Logical
      if (not r_scan_string) return false
      _add( TokenType.STRING )
      return false

    method r_scan_string->Logical
      while ((_scanner.has_another and (not _scanner.next_is('"'))))
        if (not r_scan_character) return false
      endWhile
      _must_consume( '"' )
      return true

    method r_tokenize_character_or_string->Logical
      if (_scanner.consume('\''))
        _add( TokenType.STRING )
        return false
      endIf
      if (not r_scan_character) return false
      if (_scanner.consume('\''))
        _add( TokenType.CHARACTER )
        return false
      endIf
      while ((_scanner.has_another and (not _scanner.next_is('\''))))
        if (not r_scan_character) return false
      endWhile
      _must_consume( '\'' )
      _add( TokenType.STRING )
      return false

    method r_scan_single_quote_string->Logical
      while ((_scanner.has_another and (not _scanner.next_is('\''))))
        if (not r_scan_character) return false
      endWhile
      _must_consume( '\'' )
      return true

    method r_tokenize_two_quote_string->Logical
      if (not r_scan_two_quote_string) return false
      _add( TokenType.STRING )
      return false

    method r_scan_two_quote_string->Logical
      while ((_scanner.has_another and (not _next_is("''"))))
        if (not r_scan_character) return false
      endWhile
      _must_consume( "''" )
      return true

    method r_scan_character->Logical
      if ((not _scanner.has_another))
        _throw_syntax_error("Unterminated string - unexpected end of file.")
        return false
      endIf
      ch = _scanner.read
      if ((ch=='\n'))
        _throw_syntax_error("Unterminated string - unexpected end of line.")
        return false
      endIf
      if ((ch!='\\'))
        buffer.print(ch)
        return true
      endIf
      if (_scanner.consume('b'))
        buffer.print(8->Character)
        return true
      endIf
      if (_scanner.consume('e'))
        buffer.print(27->Character)
        return true
      endIf
      if (_scanner.consume('f'))
        buffer.print(12->Character)
        return true
      endIf
      if (_scanner.consume('n'))
        buffer.print('\n')
        return true
      endIf
      if (_scanner.consume('r'))
        buffer.print('\r')
        return true
      endIf
      if (_scanner.consume('t'))
        buffer.print('\t')
        return true
      endIf
      if (_scanner.consume('v'))
        buffer.print(11->Character)
        return true
      endIf
      if (_scanner.consume('0'))
        buffer.print(0->Character)
        return true
      endIf
      if (_scanner.consume('/'))
        buffer.print('/')
        return true
      endIf
      if (_scanner.consume('?'))
        buffer.print('?')
        return true
      endIf
      if (_scanner.consume('\''))
        buffer.print('\'')
        return true
      endIf
      if (_scanner.consume('\\'))
        buffer.print('\\')
        return true
      endIf
      if (_scanner.consume('"'))
        buffer.print('"')
        return true
      endIf
      if (_scanner.consume('x'))
        hex2 = 0
        if (not r_read_hex2) return false
        buffer.print(hex2->Character)
        return true
      endIf
      if (_scanner.consume('u'))
        if (not r_read_hex4) return false
        buffer.print(hex4->Character)
        return true
      endIf
      if (_scanner.consume('['))
        hex_digit = 0
        if (not r_read_hex_digit) return false
        value = hex_digit
        digits = 1
        while (((digits<6) and _scan_pattern_18.is_next(_scanner)))
          if (not r_read_hex_digit) return false
          value = ((value * 16) + hex_digit)
          ++digits
        endWhile
        _must_consume( ']' )
        buffer.print(value->Character)
        return true
      endIf
      buffer.clear
      buffer.print ""
      buffer.print("Invalid escape sequence '\\")
      buffer.print(ch)
      buffer.print("'. Supported: \\b \\e \\f \\n \\r \\t \\v \\0 \\? \\/ \\' \\\\ \\\" \\xHH \\uHHHH \\[H*].")
      _throw_syntax_error(buffer)
      return false

    method r_read_hex4->Logical
      if (not r_read_hex2) return false
      hex4 = (hex2 * 256)
      if (not r_read_hex2) return false
      hex4 = (hex4 + hex2)
      return true

    method r_read_hex2->Logical
      if (not r_read_hex_digit) return false
      hex2 = (hex_digit * 16)
      if (not r_read_hex_digit) return false
      hex2 = (hex2 + hex_digit)
      return true

    method r_read_hex_digit->Logical
      if ((not _scan_pattern_18.is_next(_scanner)))
        _throw_syntax_error("Hex digit expected (0-9, a-f, or A-F).")
        return false
      endIf
      ch = _scanner.read
      if (((ch>='a') and (ch<='f')))
        hex_digit = ((ch - 'a'->Int) + 10)
      elseIf (((ch>='A') and (ch<='F')))
        hex_digit = ((ch - 'A'->Int) + 10)
      else
        hex_digit = (ch - '0'->Int)
      endIf
      return true

    method r_tokenize_verbatim_string->Logical
      if (not r_scan_verbatim_string) return false
      _add( TokenType.STRING )
      return false

    method r_scan_verbatim_string->Logical
      while (_scanner.has_another)
        _scan_pattern_3.scan(_scanner,buffer)
        _save_position
        _scanner.consume('\n')
        _scan_pattern_19.scan(_scanner)
        if ((not _scanner.consume('|')))
          _restore_position
          return true
        else
          _discard_position
          buffer.print('\n')
        endIf
      endWhile
      return true

endClass
